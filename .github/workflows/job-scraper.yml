name: Job Scraper

on:
  # Run automatically every 1 hours
  schedule:
    - cron: '0 */1 * * *'
  
  # Allow manual triggering through the GitHub UI
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '16'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      # Install Chromium since we're using Puppeteer
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser
      
      - name: Run job scraper
        env:
          EMAIL_USER: ${{ secrets.EMAIL_USER }}
          EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
          RECIPIENT_EMAIL: ${{ secrets.RECIPIENT_EMAIL }}
          PUPPETEER_SKIP_CHROMIUM_DOWNLOAD: true
          PUPPETEER_EXECUTABLE_PATH: /usr/bin/chromium-browser
        run: node index.js
      
      # Commit and push changes to jobs-database.json
      - name: Commit and push if changes
        run: |
          git config --global user.name 'GitHub Action'
          git config --global user.email 'action@github.com'
          git add jobs-database.json
          git diff --quiet && git diff --staged --quiet || (git commit -m "Update jobs database [skip ci]" && git push)
